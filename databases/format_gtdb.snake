##########################
#
# format_gtdb.snake
#
# Formats the latest GTDB database for last and/or diamond
#  Uses prokka to predict and annotate genes
#
# first run download_gtdb.snake to get the necessary files
#
# a large number of files are written to the working directory in
# "GTDB/{release}"
##########################
import re
import pandas
from Bio import SeqIO
from edl.gtdb import generate_taxdump

# where to put the formatted files:
seqdb_root = config.get('seqdb_root','seqdbs')
# where to get the downloaded files:
download_root = config.get('download_root', seqdb_root)
# local disk to do heavy file-related processing
work_root = config.get('work_root', seqdb_root)
# compile a nucleotide DB
build_nucl_db = config.get('build_nucl_db', False)

# version number
release = str(config.get('release', 89.0))
rel = release.split(".")[0]
fmt_threads = config.setdefault('fmt_threads', 20)

# already downloaded files
download_dir = os.path.join(download_root, 'GTDB', release)
seqdb_dir = os.path.join(seqdb_root, 'GTDB', release)
gtdb_tarball = "{download_dir}/gtdbtk_r{rel}_data.tar.gz".format(**locals())

# get list of genomes
tax_table = download_dir + f"/sp_clusters_r{rel}.tsv"
logger.debug("PARSING GTDB tax table...")
genome_tax_table = pandas.read_csv(tax_table, \
                                   sep='\t', \
                                   skiprows=config.get('skiprows', None),
                                   nrows=config.get('nrows', None),
                                   index_col=0, \
                                   usecols=[0,1,2], \
                                   names=['genome','species','lineage'], \
                                   header=0)
genome_taxonomy = {re.sub(r'^(RS|GB)_', '', g):t + ";" + s \
                   for g,s,t in genome_tax_table.itertuples()}
orgid_to_genome = {re.sub(r'\.\d+$', '', g):g \
                   for g in genome_taxonomy}
logger.debug("FOUND %d organisms in GTDB tax table." % (len(orgid_to_genome)))

"""
genome_set = set(pandas.read_csv(tax_table, \
                                 sep='\t', \
                                 usecols=[0,], \
                                 index_col=0).index)
orgids = [re.sub(r'\.\d+$', '', g) for g in genome_set]
"""

# file names
outputs = config.setdefault('outputs', set())
work_dir = work_root + "/GTDB/" + release
name_root = seqdb_dir + "/gtdb_r" + release
faa_file = name_root + ".faa"
fna_file = name_root + ".genomic.fna"

# taxonomy files
tax_map_file = seqdb_dir + "/taxdump/gtdb.acc.to.taxid"
tax_map_nucl = seqdb_dir + "/taxdump/gtdb.genomic.to.taxid"
names_dmp = seqdb_dir + "/taxdump/names.dmp"
nodes_dmp = seqdb_dir + "/taxdump/nodes.dmp"

# formatting for last and diamond happends here
config['dbs'] = {'GTDB': {'fasta': faa_file, \
                          'is_prot': True,
                          'links': {'.tax': tax_map_file, \
                                    '.ids': True, \
                                    'names.dmp': names_dmp, \
                                    'nodes.dmp': nodes_dmp}}}

# optinally create a nucleotide version
if build_nucl_db:
    config['dbs']['GTDB_nucl'] = {
        'fasta': fna_file,
        'is_prot': False,
        'links': {'.tax': tax_map_nucl,
                  '.ids': True,
                  'names.dmp': names_dmp,
                  'nodes.dmp': nodes_dmp,
                 }
    }

# formatted dbs are added to outputs in the format_dbs snakefile
include: 'format_dbs.snake'

logger.debug("OUTPUTS: \n    " + "\n    ".join(outputs))

# first rule defines the default outputs
rule outputs:
    input: outputs

rule taxonomy:
    input:
        genes=faa_file
    output:
        names=names_dmp,
        nodes=nodes_dmp,
        tax_map=tax_map_file
    benchmark:
        'benchmarks/{}/taxonomy.time'.format(release)
    run:
        logger.debug("generate_taxdump('{input.genes}')")
        generate_taxdump(fasta=input.genes, \
                         dump=os.path.join(seqdb_dir, 'taxdump'))


localrules: genes_faa, unpack

rule genes_faa:
    input: expand(work_dir + "/prokka/{orgid}/{orgid}.renamed.faa", \
                  orgid = orgid_to_genome.keys(), **locals())
    output: faa_file
    benchmark: f'benchmarks/{release}/concatenate_faa.time'
    #shell: "rm {output}; for F in {input} ; do echo $F >> {output}; done"
    run:
        if len(input) == 0:
            raise Exception("There are no input files!!!")
        input_iter = iter(input)
        input_file = next(input_iter)
        shell("cat {input_file} > {output}")
        for input_file in input_iter:
            shell("cat {input_file} >> {output}")

rule rename_faa:
    input:
        faa=work_dir + "/prokka/{orgid}/{orgid}.faa",
        tax_table=tax_table
    output: work_dir + "/prokka/{orgid}/{orgid}.renamed.faa"
    benchmark: f'benchmarks/{release}/prokka/{{orgid}}/rename.faa.time'
    run:
        # the tax table has already been parsed, so let's not re-do it here
        lineage = genome_taxonomy[orgid_to_genome[wildcards.orgid]]
        lineage = re.sub(' ','_',lineage)
        with open(output[0], 'wt') as out_handle:
            gene_count = 0
            for gene in SeqIO.parse(input.faa, 'fasta'):
                gene_count += 1
                gene_id, function = gene.description.split(None, 1)
                gene_no = int(gene.id.split("_", 1)[1])
                gene.id = '{org}_{N:07d}'.format(org=wildcards.orgid, N=gene_no)
                gene.description = '{tax} {function}' \
                    .format(tax=lineage, function=function)
                out_handle.write(gene.format('fasta'))
        logger.debug("renamed %d genes in %s" % (gene_count, wildcards.orgid))

# where the fasta files get unpacked to
GENOME_FNA_TEMPLATE= f"{work_dir}/release{rel}/fastani/database/{{genome}}_genomic.fna"

def get_domain(wildcards):
    return genome_taxonomy[orgid_to_genome[wildcards.orgid]] \
            .split(";")[0].split("__")[1]

def add_prefix_to_genome(genome):
    """
        after rel 95, there are subdirs inserted before the genome name,
        so there are two cases
    """
    if float(rel) > 100:
        genome = f"{genome[:3]}/{genome[4:7]}/{genome[7:10]}/{genome[10:13]}/{genome}"
    return genome

def get_org_genome_fna(wildcards):
    """ input fuction to get path to genomic fasta for wildcards.orgid

        just calls function below with wildcards.orgid
    """
    return get_genome_fna_from_orgid(wildcards.orgid)

def get_genome_fna_from_orgid(orgid):
    """ fuction to get path to genomic fasta for given orgid """
    genome = orgid_to_genome[orgid]

    # add prefix to genome if needed
    return GENOME_FNA_TEMPLATE.format(genome=add_prefix_to_genome(genome))

rule prokka:
    input: get_org_genome_fna
    output: work_dir + "/prokka/{orgid}/{orgid}.faa"
    benchmark: f"benchmarks/{release}/prokka/{{orgid}}/faa.time"
    params:
        kingdom=get_domain,
        outdir=lambda w: "{work_dir}/prokka/{orgid}" \
                    .format(work_dir=work_dir, orgid=w.orgid)
    threads: config.get("prokka_threads", 5)
    shell: """
        export LD_LIBRARY_PATH=$CONDA_PREFIX/lib
        prokka --outdir={params.outdir} --prefix {wildcards.orgid} \
               --kingdom={params.kingdom} --force {input} --cpus {threads} \
            > {output}.log 2>&1
        """

## GENOMIC
rule compile_genomic_fna:
    input: [get_genome_fna_from_orgid(o) for o in orgid_to_genome.keys()]
    output: fna_file
    benchmark: f"benchmarks/{release}/genomic.fna.time"
    run:
        with open(str(output), 'wt') as FNA_OUT:
            for orgid in orgid_to_genome.keys():
                org_fna = get_genome_fna_from_orgid(orgid)
                contig_count = 0
                for contig in SeqIO.parse(org_fna, 'fasta'):
                    contig_count += 1
                    contig.id = f"{orgid}_{contig_count:04d}"
                    FNA_OUT.write(contig.format('fasta'))

rule taxonomy_genomic:
    input:
        ids=f"{fna_file}.headers",
        taxids=tax_map_file,
    output:
        tax_map_nucl
    benchmark:
        'benchmarks/{}/taxonomy.nucl.time'.format(release)
    run:
        # Load gene taxid map and save taxid for each orgid
        org_taxids = {}
        with open(str(input.taxids)) as TAX:
            for line in TAX:
                gene, taxid = line.strip().split()
                orgid = re.sub(r'_\d+$', '', gene)
                org_taxids[orgid] = int(taxid)

        # PArse headesr file and assign taxid to each contig
        with open(str(output), 'wt') as OUTPUT:
            with open(str(input.ids)) as IDS:
                for line in IDS:
                    contig = line.split(None, 1)[0]
                    orgid = re.sub(r'_\d+$', '', contig)
                    taxid = org_taxids[orgid]
                    OUTPUT.write(f"{contig}\t{taxid}\n")

rule gunzip:
    input: "{gzroot}_genomic.fna.gz"
    output: "{gzroot}_genomic.fna"
    shell:
        "gunzip -c {input} > {output}"

rule unpack:
    """
    Unpacks the big archive and touches all the gzipped genome fna files so that
    we don't unpack again when rerun

    TODO: just touch the files listed in output
    """
    input: gtdb_tarball
    output: expand(GENOME_FNA_TEMPLATE + ".gz", \
                   genome=[add_prefix_to_genome(g) for g in orgid_to_genome.values()], \
                  )
    benchmark: f'benchmarks/{release}/unpack.tarball.time'
    shell:
        """tar -C {work_dir} -zxf {input}
           find {work_dir}/release{rel}/fastani/database -type f -name "*genomic.fna.gz" \
                | xargs touch
        """

